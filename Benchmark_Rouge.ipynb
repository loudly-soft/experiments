{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Benchmark-Rouge.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1zI0cMICgLQTIyZe77P1fsP1OTm4m16CQ",
      "authorship_tag": "ABX9TyPa0zcbjViujewLt83/U9hN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b7497954702641df9d81d8cc532ada76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_878c487867df48eea97750d0c26a0695",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_7a6802e5d97540d99a9cf067ea8f7c8c",
              "IPY_MODEL_04f2b82834044b6b96080d6eef7081f2",
              "IPY_MODEL_b2dca2a09ad548b0b4f8c5b17db4e15a"
            ]
          }
        },
        "878c487867df48eea97750d0c26a0695": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7a6802e5d97540d99a9cf067ea8f7c8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_595f7e5409a840a4bbea81bc84a87f8a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4d0509f14ca94a47b1d816fb89344a64"
          }
        },
        "04f2b82834044b6b96080d6eef7081f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_631670c12a744e1288240a697ff3d839",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 5622,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 5622,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c5d104f22d3844f7a9a3fa968b20931d"
          }
        },
        "b2dca2a09ad548b0b4f8c5b17db4e15a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ecb0b036ab744867bf3e4ac6f03cce70",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 5622/5622 [01:52&lt;00:00, 57.41it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1410f2b3d3ef4e34aa066b82a09fb70c"
          }
        },
        "595f7e5409a840a4bbea81bc84a87f8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4d0509f14ca94a47b1d816fb89344a64": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "631670c12a744e1288240a697ff3d839": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c5d104f22d3844f7a9a3fa968b20931d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ecb0b036ab744867bf3e4ac6f03cce70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1410f2b3d3ef4e34aa066b82a09fb70c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/loudly-soft/nlp-experiments/blob/main/Benchmark_Rouge.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tLaRRWIeKhh2"
      },
      "source": [
        "# Benchmark Text Summarisation with Rouge\n",
        "\n",
        "My self-learning notes on how to use Rouge to benchmark text summarisation and where to get ground truth data to test your model.\n",
        "\n",
        "**Synopsis**\n",
        "\n",
        "1. Download news summary dataset\n",
        "2. Implement pivoted QR algorithm [1] to summarize news from multiple sources\n",
        "3. Calculate precision, recall and F1-score with Rouge\n",
        "\n",
        "**Catalog of NLP Datasets**\n",
        "* https://metatext.io/datasets-list/summarization-task\n",
        "\n",
        "**Rouge Tutorials**\n",
        "* https://towardsdatascience.com/the-ultimate-performance-metric-in-nlp-111df6c64460\n",
        "* https://kavita-ganesan.com/what-is-rouge-and-how-it-works-for-evaluation-of-summaries/#.YVcnVZ1KiUk\n",
        "\n",
        "**References**\n",
        "\n",
        "[1] Conroy J, O’Leary D., Text Summarization via Hidden Markov Models and Pivoted QR Matrix Decomposition.  Technical Report, University of Maryland, College Park, Maryland, March, 2001."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ofzSgWyJ4dGA"
      },
      "source": [
        "## Download ground truth data for text summarisation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BJRjzyyD-gru"
      },
      "source": [
        "I will be using the multi-document summarisation dataset from:\n",
        "\n",
        "* https://github.com/Alex-Fabbri/Multi-News\n",
        "\n",
        "Each news summary is generated from multiple source articles.  There is a preprocessed and an unprocessed version of the data.  Both versions are divided into train, test and validation dataset with summaries and source articles.\n",
        "\n",
        "For this demo, I'll work with the unprocessed version of validation data:\n",
        "* https://drive.google.com/drive/folders/1uDarzpu2HFc-vjXNJCRv2NIHzakpSGOw\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "syef00OL7-B0",
        "outputId": "5b5a033f-4fb1-4178-aa0c-0be039b01c06"
      },
      "source": [
        "!gdown --id 1Y1lBbBU5Q0aJMqLhYEOdEtTqQ85XnRRM\n",
        "!gdown --id 1L2dk4ThZ-Bau9rIQpMG8I75R15FpLE-B"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1Y1lBbBU5Q0aJMqLhYEOdEtTqQ85XnRRM\n",
            "To: /content/val.tgt\n",
            "7.30MB [00:00, 114MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1L2dk4ThZ-Bau9rIQpMG8I75R15FpLE-B\n",
            "To: /content/val.src\n",
            "67.2MB [00:00, 208MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bytTtFMj_qFH"
      },
      "source": [
        "The files are:\n",
        "* `val.tgt` - summaries\n",
        "* `val.src` - source articles\n",
        "\n",
        "Count number of lines in files for sanity check"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-1Z4LGjw_qTR",
        "outputId": "7c515e59-3dcc-4f5f-917c-ccfd9190c034"
      },
      "source": [
        "!wc -l val.tgt\n",
        "!wc -l val.src"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5622 val.tgt\n",
            "5622 val.src\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vzoxPTvCBWwX"
      },
      "source": [
        "#### Disable horizontal scroll bar so long output in Colab is wrapped\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Of7gL78BBVc4"
      },
      "source": [
        "from IPython.display import HTML, display\n",
        "\n",
        "def set_css():\n",
        "  display(HTML('''<style>pre { white-space: pre-wrap; }</style>'''))\n",
        "get_ipython().events.register('pre_run_cell', set_css)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bodVuASPAEc6"
      },
      "source": [
        "#### Extract source articles and summaries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zh3qGtGuDvcd"
      },
      "source": [
        "The source file `val.src` has multiple stories per line delimited by '|||||' and line breaks are encoded as 'NEWLINE_CHAR'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 905
        },
        "id": "5QeWT6V9Dulu",
        "outputId": "cecf1f3a-317c-42bc-8533-64be6f4590c9"
      },
      "source": [
        "multi_sources = []\n",
        "\n",
        "with open('val.src', 'r', encoding='UTF-8') as file:\n",
        "  for line in file:\n",
        "    articles = line.strip().split('|||||')\n",
        "    # replace NEWLINE_CHAR and sort source articles by increasing length\n",
        "    multi_sources.append(sorted([text.replace('NEWLINE_CHAR', '\\n').strip() for text in articles if text], key=len))\n",
        "\n",
        "# show the first source stories\n",
        "for i, article in enumerate(multi_sources[0]):\n",
        "  print('Source %d' % i)\n",
        "  print('---------')\n",
        "  print(article.replace('\\n', ' '))\n",
        "  print()\n",
        "  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<style>pre { white-space: pre-wrap; }</style>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Source 0\n",
            "---------\n",
            "A charity shop is urging people to stop donating The Da Vinci Code after becoming overwhelmed with copies.      The Oxfam shop in Swansea has been receiving an average of one copy of the Dan Brown novel a week for months, leaving them with little room for any other books.      Staff who are struggling to sell copies of the book have put a note up in the store saying they would rather donors hand in their vinyl instead.\n",
            "\n",
            "Source 1\n",
            "---------\n",
            "Whether a sign of a good read; or a comment on the 'pulp' nature of some genres of fiction, the Oxfam second-hand book charts have remained in The Da Vinci Code author's favour for the past four years.      Dan Brown has topped Oxfam's 'most donated' list again, his fourth consecutive year. Having sold more than 80 million copies of The Da Vinci Code and had all four of his novels on the New York Times bestseller list in the same week, it's hardly surprising that Brown's hefty tomes are being donated to charity by readers keen to make some room on their shelves.      Another cult crime writer responsible to heavy-weight hardbacks, Stieg Larsson, is Oxfam's 'most sold' author for the second time in a row. Both the 'most donated' and 'most sold' lists are dominated by crime fiction, trilogies and fantasy, with JK Rowling the only female author listed in either of the Top Fives.      Click here or on \"View Gallery\" to see both charts in pictures\n",
            "\n",
            "Source 2\n",
            "---------\n",
            "A woman reads a copy of the newly released book ''The Lost Symbol'' by Dan Brown, at a speed reading book launch event in Sydney, September 15, 2009. REUTERS/Tim Wimborne      SAN FRANCISCO The latest novel from \"Da Vinci Code\" author Dan Brown, \"The Lost Symbol,\" broke one-day sales records, its publisher and booksellers said.      Readers snapped up over one million hardcover copies across the United States, Canada and the United Kingdom after it was released on Tuesday, said publisher Knopf Doubleday, a division of Random House Inc.      \"We are seeing historic, record-breaking sales across all types of our accounts in North America for 'The Lost Symbol,\" said Sonny Mehta, editor in chief of Knopf Doubleday Publishing Group. Knopf Doubleday is a division of Random House Inc.      Amazon.com Inc, the world's largest online retailer, called the book its bestselling first-day adult fiction title ever, including pre-orders.      Barnes & Noble Inc said \"The Lost Symbol\" broke its previous one-day sales record for adult fiction.      The success of the Dan Brown's latest is a boost to publisher Knopf Doubleday and booksellers, which have endured sliding sales in the midst of the recession.      Booksellers have anxiously awaited a popular title that will resonate with readers and fuel the same sort of frenzy seen earlier this decade with the \"Harry Potter\" series, from author J.K. Rowling.      But the $25 billion domestic book market has wallowed in a slump in recent years as more readers make their purchases online, or forego books altogether for online games and other forms of media and entertainment.      Now, digital books and electronic reading devices such as Amazon's Kindle or Sony Corp's Reader are seen as both avenues of growth and sources of competition for traditional media, and publishers and booksellers are scrambling to respond.      The highly anticipated book from Brown comes six years after the release of the American novelist's last book \"The Da Vinci Code\". It follows the adventures of Harvard professor Robert Langdon and is set in the secret world of Freemasons in Washington D.C.      \"The Da Vinci Code\" sold 80 million copies worldwide. It was made into a film starring Tom Hanks that grossed more than $758 million, according to tracking firm Box Office Mojo.      Shares of Amazon closed up $7.15 to $90.70 on the Nasdaq. Amazon was upgraded to a \"Buy\" rating by Bank of America Merrill Lynch, which cited a resurgence in e-commerce that would benefit the Seattle-based company.      Barnes & Noble closed up 14 cents to $22.04 and book retailer Borders Group Inc closed up 2 cents to $3.29, on the New York Stock Exchange.      (Reporting by Alexandria Sage; editing by Carol Bishopric)\n",
            "\n",
            "Source 3\n",
            "---------\n",
            "Bestselling author is also the most frequently given away to charity shops      Dan Brown might be one of the world's bestselling authors but it turns out that readers aren't too keen on keeping his special blend of religious conspiracy and scholarly derring-do on their shelves once they've bought it.      Brown, who has sold more than 81m copies of The Da Vinci Code worldwide, has been revealed as the most donated author to Oxfam's 700 high street shops. With just four books to his name – although his long-awaited fifth The Lost Symbol is published next month – Brown did well to see off competition from John Grisham, author of more than 20 and the second-most likely writer to be ditched in a charity shop by readers.      But as secondhand bookshop shelves flood with battered editions of Angels and Demons and Digital Fortress, Brown can comfort himself with the fact that he's also Oxfam's second most bought author: there are, apparently, still readers out there who have yet to follow the adventures of the dapper symbologist Robert Langdon. There's no such consolation for Grisham, whose legal thrillers fail to make Oxfam's bestseller charts at all.      \"There's no question that when you go into the back room of Oxfam shops there are many Dan Brown books,\" said Oxfam's director of trading David McCullough. \"But he's also very high on the bestseller list so there is a useful recycling exercise going on – it's not just people saying 'I've read The Da Vinci Code and now I must get rid of it'.\"      Ian Rankin, whose dour, boozy detective John Rebus is no Robert Langdon, tops Oxfam's bestseller list, which the charity says is the first ever high-street secondhand bestseller chart. \"It's always good for an author to know that their books are popular,\" said the Scottish author, who will unveil a new policeman hero, the teetotal Malcolm Fox, next month. \"With Oxfam, it's also heartening to realise that each book donated and bought is helping such a worthwhile organisation.\"      Stephenie Meyer, author of the Twilight series and instigator of myriad teenage crushes courtesy of her sparkly vampire hero Edward Cullen, is also sitting high in Oxfam's charts, nestling between Bernard Cornwell and Terry Pratchett.      Margaret Atwood, meanwhile, winner of the Booker prize and author of a host of critically acclaimed works of fiction, scrapes into the list in eighth place, keeping unlikely company with thriller powerhouse James Patterson – currently producing at least eight books a year thanks to a horde of co-writers – and Jodi Picoult, never afraid to jerk a tear or pile on the plot twists.      \"We just need to dispel the idea that we are sitting there in Oxfam with only first editions of literary gems – actually we've got shelves of really good fiction,\" said McCullough. \"Waterstone's might be more upset than secondhand booksellers,\" he added, referring to the recent slew of complaints from secondhand booksellers that the charity is stealing their business.      Oxfam, Europe's biggest high-street retailer of secondhand books and the third-biggest bookseller in the UK, launched a drive for book donations in May ahead of its first national book festival, Bookfest, in July. Authors including Joanna Trollope, Philip Pullman and Jonathan Coe all lent a hand in shops across the country as part of the festival, and the drive saw book donations rise 40%, with sales up by more than 10%.      Rare books and first editions have also been pouring into shops since May. Ten of the most sought-after editions have raised more than £4,500 for the charity between them. A first edition of Lord of the Rings sold for £800, a first edition of Watership Down brought in £500, Sylvia Plath's Ariel sold for £350, Ian Fleming's From Russia With Love for £300 and a second printing of Martin Chuzzlewit for £200.      Oxfam, which has more than 130 specialist bookshops and stocks books in almost all of its 700 stores, sells £1.6m-worth of books a month – equivalent, it says, to 50,000 emergency shelters, 64,000 goats or safe water for 2.1 million people.      The most donated authors to Oxfam shops so far this year:      1. Dan Brown      2. John Grisham      3. Ian Rankin      4. Danielle Steel      5. Helen Fielding      6. Stephen King      7. JK Rowling      8. Catherine Cookson      9. Patricia Cornwell      10. Mills & Boon      The Oxfam shop bestseller list:      1. Ian Rankin      2. Dan Brown      3. Bernard Cornwell      4. Stephanie Meyer      5. Terry Pratchett      6. Khaled Hosseini      7. Helen Fielding      8. Margaret Atwood      9. James Patterson      10. Jodi Picoult      The top 10 most valuable donated books since May:      1. JRR Tolkien, Lord of the Rings – first edition, sold for £800      2. Don Giovanni sheet music – first edition, sold for £750      3. Sowerby's Catalogue of Shells – sold for £600      4. Richard Adams, Watership Down – first edition, sold for £500      5. Handbook of Indian Dances - first edition with hand-blocked prints, sold for £500      6. Richmal Crompton, Just William - first edition, sold for £440      7. Sylvia Plath, Ariel – first edition, sold for £350      8. Ian Fleming, From Russia With Love – first edition, sold for £300      9. Charles Dickens, Martin Chuzzlewit – second print, sold for £200      10. WE Johns, Biggles in Australia – first edition, sold for £150\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "63ER3hUQDmTV"
      },
      "source": [
        "The summary file `val.tgt` has 1 summary per line"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "id": "OWbgabzLAEmy",
        "outputId": "1d7a1cbd-7026-408b-e572-49aac92649ee"
      },
      "source": [
        "summaries = []\n",
        "with open('val.tgt', 'r', encoding='UTF-8') as file:\n",
        "  for line in file:\n",
        "    summaries.append(line.rstrip()[2:])\n",
        "\n",
        "# show the first summary\n",
        "print(summaries[0])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<style>pre { white-space: pre-wrap; }</style>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Da Vinci Code has sold so many copies—that would be at least 80 million—that it's bound to turn up in book donation piles. But at one charity shop in the UK, it's been donated so heavily that the shop has posted a sign propped up on a tower of Da Vinci Code copies that reads: \"You could give us another Da Vinci Code... but we would rather have your vinyl!\" The manager of the Oxfam shop in Swansea tells the Telegraph that people are laughing and taking pictures of the sizable display: \"I would say that we get one copy of the book every day.\" He says people buy them \"occasionally,\" but with vinyl sales up 25% in the past year, they'd rather take records. Dan Brown's book isn't the only one that shops like Oxfam struggle to re-sell. Last year, Oxfam was hit with a large and steady supply of Fifty Shades of Grey, and it similarly begged donors: \"Please—no more.\" But Brown has a particular kind of staying power. The Da Vinci Code was published in 2003, and within six years Brown had booted John Grisham from the No. 1 slot on the list of writers whose books were most often donated to Oxfam's 700 shops, reported the Guardian at the time. The Independent in 2012 reported Brown's best-seller was the most-donated book for the fourth year running. (See why Dan Brown took heat from the Philippines.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75Bz3tltaLLQ"
      },
      "source": [
        "## Generate extractive summaries\n",
        "\n",
        "The algorithm is QR decomposition with column pivoting from numerical linear algebra [1].  The algorithm selects key sentences and ranks them in order of importance.  The idea is to find the most important sentence (biggest L2 norm) and extract it for summary.  From the remaining sentences, extract the next sentence that is important and different (orthogonal) to the extracted ones.  Repeat until enough key sentences are extracted.\n",
        "\n",
        "I'm curious how this approach will fare on multi-document summary.  Would it be able to ignore conceptually similar sentences from different sources when the sources are combined into a single text to summarize?\n",
        "\n",
        "**References**\n",
        "\n",
        "[1] Conroy J, O’Leary D., Text Summarization via Hidden Markov Models and Pivoted QR Matrix Decomposition.  Technical Report, University of Maryland, College Park, Maryland, March, 2001.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-I4Qfx0pglAH"
      },
      "source": [
        "#### Implement pivoted QR decomposition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 16
        },
        "id": "wqrbS81dlHnF",
        "outputId": "b40d23ba-5ab3-468a-bc65-c18a0ef77904"
      },
      "source": [
        "from numpy import linalg as LA\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def givens_vector(x, start_pos, eps=0.0000001):\n",
        "  \"\"\"Apply givens rotation to zero out elements of vector x from starting position\"\"\"\n",
        "\n",
        "  size = len(x)\n",
        "  G_acc = np.eye(size)\n",
        "  for i in range(size-1, start_pos-1, -1):\n",
        "    if x[i-1] < eps and x[i] < eps:\n",
        "      continue\n",
        "    # init givens matrix\n",
        "    c = x[i-1] / pow(pow(x[i-1], 2) + pow(x[i], 2), 0.5)\n",
        "    s = x[i] / pow(pow(x[i-1], 2) + pow(x[i], 2), 0.5)\n",
        "    G = np.eye(size)\n",
        "    G[i-1, i-1] = c\n",
        "    G[i-1, i] = s \n",
        "    G[i, i-1] = -s\n",
        "    G[i, i] = c\n",
        "    x = G.dot(x)\n",
        "    # stack the givens matrices\n",
        "    G_acc = np.matmul(G, G_acc)\n",
        "  return G_acc, x\n",
        "\n",
        "\n",
        "def extract_columns(W, max_cols, seed_col_index=None, eps=0.0000001):\n",
        "  \"\"\"Extract orthogonal columns with biggest L2 norm\"\"\"\n",
        "\n",
        "  selected_col_indices = []\n",
        "  col_indices = list(range(W.shape[1]))\n",
        "  while len(selected_col_indices) < max_cols and len(col_indices) > 0:\n",
        "    l2_norms = LA.norm(W, axis=0)\n",
        "    if seed_col_index is None:\n",
        "      # pick column of W with highest L2 norm\n",
        "      j = np.argmax(l2_norms)\n",
        "    else:\n",
        "      j = seed_col_index\n",
        "      seed_col_index = None\n",
        "    if l2_norms[j] < eps:\n",
        "      break\n",
        "    selected_col_indices.append(col_indices[j])\n",
        "    del col_indices[j]\n",
        "    # apply givens rotation to selected column\n",
        "    G, _ = givens_vector(W[:,j], len(selected_col_indices))\n",
        "    # apply givens rotation to remaining columns\n",
        "    W = np.matmul(G, np.delete(W, j, 1))\n",
        "  return selected_col_indices\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<style>pre { white-space: pre-wrap; }</style>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FmbJxHPtZKmL"
      },
      "source": [
        "A simple test to show that the heaviest (biggest L2 norm) column is chosen first, then the next heaviest column orthogonal to the chosen column is selected, then the next column orthogonal to all the chosen columns."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "Vgn1o0SlZLAr",
        "outputId": "c83df5f1-a893-4161-f14c-e6e8fd8d6dbc"
      },
      "source": [
        "X = np.array([\n",
        " [0, 0, 1],\n",
        " [0, 0, 1],\n",
        " [0, 0, 1],\n",
        " [0, 1, 0],\n",
        " [0, 1, 0],\n",
        " [1, 0, 0]])\n",
        "\n",
        "extract_columns(X, max_cols=3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<style>pre { white-space: pre-wrap; }</style>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2, 1, 0]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s0W9yCRjSZyh"
      },
      "source": [
        "#### Functions to vectorize text to term-sentence matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "cmv2Ca3bSZ8h",
        "outputId": "af86cb79-5b89-4478-fdf8-8e088c8d3efb"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "\n",
        "def vectorize(sentences, truncateSVD=True, threshold=0.8):\n",
        "  \"\"\"Convert sentences to term-sentence matrix and reduce noise with SVD\"\"\"\n",
        "\n",
        "  vectorizer = CountVectorizer(stop_words=\"english\", strip_accents='ascii')\n",
        "  W = vectorizer.fit_transform(sentences).toarray().transpose().astype(float)\n",
        "  \n",
        "  # truncate SVD to cover X% of singular values\n",
        "  if truncateSVD:\n",
        "    U, S, V = np.linalg.svd(W, full_matrices=True)\n",
        "    total_sigmas = sum(S)\n",
        "    subtotal = 0\n",
        "    for k, s in enumerate(S):\n",
        "      subtotal += s\n",
        "      if subtotal / total_sigmas > threshold:\n",
        "        break\n",
        "    W = V[0:k+1,:]\n",
        "    #print('%d out of %d sigmas selected' % (k+1, len(S)))\n",
        "  return W\n",
        "\n",
        "\n",
        "def parse_sentences(text):\n",
        "  \"\"\"Tokenize text into sentences\"\"\"\n",
        "\n",
        "  return [sentence.replace('\\n', ' ') for sentence in nltk.tokenize.sent_tokenize(text)]\n",
        "\n",
        "\n",
        "def summarise(W, sentences, max_sentences, seed_col_index=None):\n",
        "  \"\"\"Apply pivoted QR on term-sentence matrix\"\"\"\n",
        "\n",
        "  # sort extracted sentences by their original position in text\n",
        "  return ' '.join([sentences[i] for i in sorted(extract_columns(W, max_sentences, seed_col_index))])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<style>pre { white-space: pre-wrap; }</style>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZ3ZSqcZghxU"
      },
      "source": [
        "#### Apply algorithm to summarise news"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "b7497954702641df9d81d8cc532ada76",
            "878c487867df48eea97750d0c26a0695",
            "7a6802e5d97540d99a9cf067ea8f7c8c",
            "04f2b82834044b6b96080d6eef7081f2",
            "b2dca2a09ad548b0b4f8c5b17db4e15a",
            "595f7e5409a840a4bbea81bc84a87f8a",
            "4d0509f14ca94a47b1d816fb89344a64",
            "631670c12a744e1288240a697ff3d839",
            "c5d104f22d3844f7a9a3fa968b20931d",
            "ecb0b036ab744867bf3e4ac6f03cce70",
            "1410f2b3d3ef4e34aa066b82a09fb70c"
          ]
        },
        "id": "jS0BGIT_I9Qx",
        "outputId": "7789b660-d3ef-456e-8c1a-3c919d6d636c"
      },
      "source": [
        "from tqdm.notebook import tqdm\n",
        "\n",
        "\n",
        "summaries_test = []\n",
        "summaries_pred = []\n",
        "\n",
        "for i in tqdm(range(len(summaries))):\n",
        "#for i in tqdm(range(100)):\n",
        "\n",
        "  # tokenize sentences from source articles and combine them\n",
        "  sentences = sum([parse_sentences(text) for text in multi_sources[i]], [])\n",
        "\n",
        "  # pivoted QR algo is slow so skip long text\n",
        "  if len(sentences) <= 100:\n",
        "\n",
        "    # choose only the longest source article to summarise and tokenize sentences\n",
        "    #sentences = parse_sentences(multi_sources[i][-1])\n",
        "\n",
        "    # vectorize sentences to term-sentence matrix\n",
        "    W = vectorize(sentences, truncateSVD=True, threshold=0.2)\n",
        "\n",
        "    # set max number of summary sentences to % of the longest article\n",
        "    #max_summary_sentences = max(1, int(len(parse_sentences(multi_sources[i][-1])) * 0.20))\n",
        "\n",
        "    # set max number of summary sentences\n",
        "    max_summary_sentences = 6\n",
        "\n",
        "    # generate summary\n",
        "    summary = summarise(W, sentences, max_summary_sentences)\n",
        "    summaries_pred.append(summary)\n",
        "\n",
        "    # keep ground truth summary\n",
        "    summaries_test.append(summaries[i])\n",
        "\n",
        "print(f'{len(summaries_pred)} out of {len(summaries)} summaries generated')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<style>pre { white-space: pre-wrap; }</style>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b7497954702641df9d81d8cc532ada76",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/5622 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4385 out of 5622 summaries generated\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WpqC7ILhbK7o"
      },
      "source": [
        "Show the first summary generated by model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "CrzXIzv7bIKf",
        "outputId": "5a9fc015-6e04-475e-d5b5-7fe6371f97da"
      },
      "source": [
        "print(summaries_pred[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<style>pre { white-space: pre-wrap; }</style>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Readers snapped up over one million hardcover copies across the United States, Canada and the United Kingdom after it was released on Tuesday, said publisher Knopf Doubleday, a division of Random House Inc.      \"We are seeing historic, record-breaking sales across all types of our accounts in North America for 'The Lost Symbol,\" said Sonny Mehta, editor in chief of Knopf Doubleday Publishing Group. Bestselling author is also the most frequently given away to charity shops      Dan Brown might be one of the world's bestselling authors but it turns out that readers aren't too keen on keeping his special blend of religious conspiracy and scholarly derring-do on their shelves once they've bought it. Margaret Atwood, meanwhile, winner of the Booker prize and author of a host of critically acclaimed works of fiction, scrapes into the list in eighth place, keeping unlikely company with thriller powerhouse James Patterson – currently producing at least eight books a year thanks to a horde of co-writers – and Jodi Picoult, never afraid to jerk a tear or pile on the plot twists. Oxfam, Europe's biggest high-street retailer of secondhand books and the third-biggest bookseller in the UK, launched a drive for book donations in May ahead of its first national book festival, Bookfest, in July. A first edition of Lord of the Rings sold for £800, a first edition of Watership Down brought in £500, Sylvia Plath's Ariel sold for £350, Ian Fleming's From Russia With Love for £300 and a second printing of Martin Chuzzlewit for £200. Oxfam, which has more than 130 specialist bookshops and stocks books in almost all of its 700 stores, sells £1.6m-worth of books a month – equivalent, it says, to 50,000 emergency shelters, 64,000 goats or safe water for 2.1 million people.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y0aCnnRJIT5x"
      },
      "source": [
        "## Benchmark with Rouge\n",
        "Install `rouge` library from https://github.com/pltrdy/rouge"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "VINIitOnIUEo",
        "outputId": "6d22e4ef-5968-4d0d-a04a-85dd3560e6ce"
      },
      "source": [
        "!pip install rouge"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<style>pre { white-space: pre-wrap; }</style>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: rouge in /usr/local/lib/python3.7/dist-packages (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from rouge) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r8GGmzIIhSRT"
      },
      "source": [
        "#### Calculate precision, recall and F1-score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        },
        "id": "ZZnbN1aqduHC",
        "outputId": "963b98f1-331e-45ab-b7ce-fb24a8747ef0"
      },
      "source": [
        "from rouge import Rouge\n",
        "\n",
        "# metric 'route-l' (with an L at the end) is slow, so ignore\n",
        "rouge = Rouge(metrics=['rouge-1', 'rouge-2'])\n",
        "scores = rouge.get_scores(summaries_pred, summaries_test, avg=True)\n",
        "\n",
        "# print rouge metrics\n",
        "metric_descs = {'f':'f1-score', 'p':'precision', 'r':'recall'}\n",
        "for score_name, metrics in scores.items():\n",
        "  print(score_name.upper())\n",
        "  print('-' * 2 * len(score_name))\n",
        "  for metric_name, val in metrics.items():\n",
        "    print(f'{metric_descs[metric_name]} = {val}')\n",
        "  print()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<style>pre { white-space: pre-wrap; }</style>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROUGE-1\n",
            "--------------\n",
            "recall = 0.3233149060980245\n",
            "precision = 0.28146200003621774\n",
            "f1-score = 0.2927864440468112\n",
            "\n",
            "ROUGE-2\n",
            "--------------\n",
            "recall = 0.11167860761235997\n",
            "precision = 0.09632214048206264\n",
            "f1-score = 0.10002308729656417\n",
            "\n"
          ]
        }
      ]
    }
  ]
}